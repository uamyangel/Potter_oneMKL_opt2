#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Intel VTune ç»“æœåˆ†æå·¥å…·
ç”¨é€”: è‡ªåŠ¨è§£æ VTune æŠ¥å‘Šï¼Œæå–å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®
ä½œè€…: Claude Code
æ—¥æœŸ: 2025-10-30
"""

import os
import sys
import csv
import json
import argparse
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict


@dataclass
class HotspotFunction:
    """çƒ­ç‚¹å‡½æ•°æ•°æ®"""
    function_name: str
    cpu_time: float  # ç§’
    cpu_time_percent: float  # ç™¾åˆ†æ¯”
    module: str


@dataclass
class MemoryMetrics:
    """å†…å­˜è®¿é—®æŒ‡æ ‡"""
    l1_misses: Optional[float] = None
    l2_misses: Optional[float] = None
    l3_misses: Optional[float] = None
    dtlb_misses: Optional[float] = None
    memory_bandwidth_gb_s: Optional[float] = None


@dataclass
class ThreadingMetrics:
    """çº¿ç¨‹æŒ‡æ ‡"""
    cpu_utilization: Optional[float] = None  # ç™¾åˆ†æ¯”
    thread_count: Optional[int] = None
    wait_time_percent: Optional[float] = None
    load_imbalance: Optional[float] = None


@dataclass
class MicroarchMetrics:
    """å¾®æ¶æ„æŒ‡æ ‡"""
    cpi: Optional[float] = None  # Cycles Per Instruction
    frontend_stall_percent: Optional[float] = None
    backend_stall_percent: Optional[float] = None
    branch_mispred_percent: Optional[float] = None


@dataclass
class PerformanceAnalysis:
    """å®Œæ•´çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
    analysis_type: str
    benchmark: str
    hotspots: List[HotspotFunction]
    memory: Optional[MemoryMetrics] = None
    threading: Optional[ThreadingMetrics] = None
    microarch: Optional[MicroarchMetrics] = None
    recommendations: List[str] = None


class VTuneAnalyzer:
    """VTune ç»“æœåˆ†æå™¨"""

    def __init__(self, result_dir: Path):
        self.result_dir = result_dir
        self.analysis = None

    def parse_hotspots(self, csv_file: Path) -> List[HotspotFunction]:
        """è§£æ hotspots CSV æ–‡ä»¶"""
        hotspots = []

        if not csv_file.exists():
            return hotspots

        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # CSV åˆ—åå¯èƒ½ä¸åŒï¼Œå°è¯•å¤šç§å¯èƒ½
                    function_name = row.get('Function', row.get('Function Stack', 'Unknown'))
                    cpu_time_str = row.get('CPU Time', row.get('CPU Time:Self', '0'))
                    cpu_time_percent_str = row.get('CPU Time:Self %', row.get('% of Total', '0'))
                    module = row.get('Module', row.get('Module Name', 'Unknown'))

                    # è§£ææ—¶é—´ï¼ˆå¯èƒ½æ˜¯ "1.234s" æ ¼å¼ï¼‰
                    cpu_time = self._parse_time(cpu_time_str)
                    cpu_time_percent = self._parse_percent(cpu_time_percent_str)

                    if cpu_time > 0:
                        hotspots.append(HotspotFunction(
                            function_name=function_name,
                            cpu_time=cpu_time,
                            cpu_time_percent=cpu_time_percent,
                            module=module
                        ))
        except Exception as e:
            print(f"è­¦å‘Š: è§£æ hotspots CSV å¤±è´¥: {e}", file=sys.stderr)

        # æŒ‰ CPU æ—¶é—´æ’åº
        hotspots.sort(key=lambda x: x.cpu_time, reverse=True)
        return hotspots[:20]  # è¿”å› top 20

    def parse_summary(self) -> Dict[str, Any]:
        """è§£æ summary æŠ¥å‘Šï¼Œæå–å…³é”®æŒ‡æ ‡"""
        summary_csv = self.result_dir / "summary.csv"
        summary_data = {}

        if summary_csv.exists():
            try:
                with open(summary_csv, 'r', encoding='utf-8') as f:
                    reader = csv.reader(f)
                    for row in reader:
                        if len(row) >= 2:
                            key = row[0].strip()
                            value = row[1].strip()
                            summary_data[key] = value
            except Exception as e:
                print(f"è­¦å‘Š: è§£æ summary CSV å¤±è´¥: {e}", file=sys.stderr)

        return summary_data

    def analyze(self) -> PerformanceAnalysis:
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        # ç¡®å®šåˆ†æç±»å‹
        dir_name = self.result_dir.name
        if 'hotspots' in dir_name:
            analysis_type = 'hotspots'
        elif 'memory' in dir_name:
            analysis_type = 'memory-access'
        elif 'threading' in dir_name:
            analysis_type = 'threading'
        elif 'uarch' in dir_name:
            analysis_type = 'uarch-exploration'
        else:
            analysis_type = 'unknown'

        # æå–åŸºå‡†æµ‹è¯•åç§°
        benchmark = self._extract_benchmark_name(dir_name)

        # è§£æ hotspots
        hotspots_csv = self.result_dir / "hotspots.csv"
        hotspots = self.parse_hotspots(hotspots_csv)

        # å¦‚æœæ²¡æœ‰ hotspots.csvï¼Œå°è¯•ä» summary ä¸­æå–
        if not hotspots:
            hotspots = self._extract_hotspots_from_summary()

        # åˆ›å»ºåˆ†æå¯¹è±¡
        analysis = PerformanceAnalysis(
            analysis_type=analysis_type,
            benchmark=benchmark,
            hotspots=hotspots
        )

        # æ ¹æ®ç±»å‹è§£æç‰¹å®šæŒ‡æ ‡
        if analysis_type == 'memory-access':
            analysis.memory = self._parse_memory_metrics()
        elif analysis_type == 'threading':
            analysis.threading = self._parse_threading_metrics()
        elif analysis_type == 'uarch-exploration':
            analysis.microarch = self._parse_microarch_metrics()

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        analysis.recommendations = self._generate_recommendations(analysis)

        self.analysis = analysis
        return analysis

    def _extract_benchmark_name(self, dir_name: str) -> str:
        """ä»ç›®å½•åæå–åŸºå‡†æµ‹è¯•åç§°"""
        # ä¾‹å¦‚: "hotspots_koios_dla_like_large" -> "koios_dla_like_large"
        parts = dir_name.split('_', 1)
        if len(parts) > 1:
            return parts[1]
        return "unknown"

    def _extract_hotspots_from_summary(self) -> List[HotspotFunction]:
        """ä» summary ä¸­æå–çƒ­ç‚¹å‡½æ•°ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # å°è¯•ä½¿ç”¨ vtune å‘½ä»¤è¡Œå·¥å…·
        hotspots = []
        try:
            result = subprocess.run(
                ['vtune', '-report', 'hotspots', '-result-dir', str(self.result_dir),
                 '-format', 'csv', '-csv-delimiter', 'comma'],
                capture_output=True,
                text=True,
                timeout=30
            )
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                reader = csv.DictReader(lines)
                for row in reader:
                    function_name = row.get('Function', 'Unknown')
                    cpu_time_str = row.get('CPU Time', '0')
                    cpu_time_percent_str = row.get('% of Total', '0')
                    module = row.get('Module', 'Unknown')

                    cpu_time = self._parse_time(cpu_time_str)
                    cpu_time_percent = self._parse_percent(cpu_time_percent_str)

                    if cpu_time > 0:
                        hotspots.append(HotspotFunction(
                            function_name=function_name,
                            cpu_time=cpu_time,
                            cpu_time_percent=cpu_time_percent,
                            module=module
                        ))
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•ä» vtune å‘½ä»¤æå–çƒ­ç‚¹: {e}", file=sys.stderr)

        hotspots.sort(key=lambda x: x.cpu_time, reverse=True)
        return hotspots[:20]

    def _parse_memory_metrics(self) -> MemoryMetrics:
        """è§£æå†…å­˜è®¿é—®æŒ‡æ ‡"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„ VTune æŠ¥å‘Šæ ¼å¼æ¥è§£æ
        # ç”±äºæ ¼å¼å¯èƒ½å› ç‰ˆæœ¬è€Œå¼‚ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªæ¡†æ¶
        return MemoryMetrics()

    def _parse_threading_metrics(self) -> ThreadingMetrics:
        """è§£æçº¿ç¨‹æŒ‡æ ‡"""
        return ThreadingMetrics()

    def _parse_microarch_metrics(self) -> MicroarchMetrics:
        """è§£æå¾®æ¶æ„æŒ‡æ ‡"""
        return MicroarchMetrics()

    def _generate_recommendations(self, analysis: PerformanceAnalysis) -> List[str]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åˆ†æçƒ­ç‚¹å‡½æ•°
        if analysis.hotspots:
            top_hotspot = analysis.hotspots[0]
            if top_hotspot.cpu_time_percent > 10:
                recommendations.append(
                    f"ğŸ”¥ å…³é”®çƒ­ç‚¹: {top_hotspot.function_name} å ç”¨ {top_hotspot.cpu_time_percent:.1f}% CPU æ—¶é—´ï¼Œ"
                    f"è¿™æ˜¯ä¸»è¦ä¼˜åŒ–ç›®æ ‡"
                )

            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªé«˜å ç”¨å‡½æ•°
            high_cpu_funcs = [h for h in analysis.hotspots if h.cpu_time_percent > 5]
            if len(high_cpu_funcs) > 3:
                recommendations.append(
                    f"ğŸ“Š å‘ç° {len(high_cpu_funcs)} ä¸ªé«˜ CPU å ç”¨å‡½æ•° (>5%)ï¼Œå»ºè®®é€ä¸€ä¼˜åŒ–"
                )

        # å†…å­˜ç›¸å…³å»ºè®®
        if analysis.memory:
            if analysis.memory.l3_misses and analysis.memory.l3_misses > 20:
                recommendations.append(
                    f"ğŸ’¾ L3 ç¼“å­˜æœªå‘½ä¸­ç‡ {analysis.memory.l3_misses:.1f}% åé«˜ï¼Œ"
                    f"å»ºè®®: 1) æ·»åŠ è½¯ä»¶é¢„å– 2) ä¼˜åŒ–æ•°æ®å¸ƒå±€ 3) å‡å°‘å·¥ä½œé›†å¤§å°"
                )

            if analysis.memory.dtlb_misses and analysis.memory.dtlb_misses > 1:
                recommendations.append(
                    f"ğŸ“„ DTLB æœªå‘½ä¸­ç‡ {analysis.memory.dtlb_misses:.1f}% åé«˜ï¼Œ"
                    f"å»ºè®®å¯ç”¨ Huge Pages (2MB é¡µ)"
                )

        # çº¿ç¨‹ç›¸å…³å»ºè®®
        if analysis.threading:
            if analysis.threading.cpu_utilization and analysis.threading.cpu_utilization < 60:
                recommendations.append(
                    f"âš ï¸ CPU åˆ©ç”¨ç‡ä»… {analysis.threading.cpu_utilization:.1f}%ï¼Œ"
                    f"çº¿ç¨‹æœªå……åˆ†åˆ©ç”¨ï¼Œå»ºè®®æ£€æŸ¥è´Ÿè½½å‡è¡¡å’ŒåŒæ­¥å¼€é”€"
                )

            if analysis.threading.wait_time_percent and analysis.threading.wait_time_percent > 10:
                recommendations.append(
                    f"â³ çº¿ç¨‹ç­‰å¾…æ—¶é—´å  {analysis.threading.wait_time_percent:.1f}%ï¼Œ"
                    f"å»ºè®®: 1) å‡å°‘åŒæ­¥ç‚¹ 2) ä½¿ç”¨æ— é”æ•°æ®ç»“æ„ 3) è°ƒæ•´æ‰¹æ¬¡ç²’åº¦"
                )

        # å¾®æ¶æ„ç›¸å…³å»ºè®®
        if analysis.microarch:
            if analysis.microarch.cpi and analysis.microarch.cpi > 2.0:
                recommendations.append(
                    f"ğŸ”§ CPI (Cycles Per Instruction) = {analysis.microarch.cpi:.2f} åé«˜ï¼Œ"
                    f"è¡¨æ˜å­˜åœ¨æ€§èƒ½ç“¶é¢ˆï¼Œå»ºè®®æ·±å…¥åˆ†æå†…å­˜è®¿é—®å’ŒæŒ‡ä»¤ä¾èµ–"
                )

            if analysis.microarch.backend_stall_percent and analysis.microarch.backend_stall_percent > 30:
                recommendations.append(
                    f"ğŸš§ åç«¯åœé¡¿å  {analysis.microarch.backend_stall_percent:.1f}%ï¼Œ"
                    f"ä¸»è¦åŸå› æ˜¯å†…å­˜è®¿é—®æ…¢æˆ–æ‰§è¡Œå•å…ƒé¥±å’Œ"
                )

        if not recommendations:
            recommendations.append("âœ… æœªå‘ç°æ˜æ˜¾çš„æ€§èƒ½ç“¶é¢ˆï¼Œå¯ä»¥å°è¯•æ›´ç»†ç²’åº¦çš„åˆ†æ")

        return recommendations

    def _parse_time(self, time_str: str) -> float:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "1.234s" -> 1.234"""
        try:
            # ç§»é™¤å•ä½
            time_str = time_str.replace('s', '').replace('ms', 'e-3').replace('us', 'e-6')
            return float(time_str)
        except:
            return 0.0

    def _parse_percent(self, percent_str: str) -> float:
        """è§£æç™¾åˆ†æ¯”å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "12.34%" -> 12.34"""
        try:
            return float(percent_str.replace('%', '').strip())
        except:
            return 0.0

    def generate_markdown_report(self, output_file: Path):
        """ç”Ÿæˆ Markdown æ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        if not self.analysis:
            self.analyze()

        analysis = self.analysis

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"# VTune æ€§èƒ½åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†æç±»å‹**: {analysis.analysis_type}\n")
            f.write(f"**åŸºå‡†æµ‹è¯•**: {analysis.benchmark}\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {self._get_timestamp()}\n\n")

            f.write("---\n\n")

            # çƒ­ç‚¹å‡½æ•°
            if analysis.hotspots:
                f.write("## ğŸ”¥ CPU çƒ­ç‚¹å‡½æ•° (Top 10)\n\n")
                f.write("| æ’å | å‡½æ•°å | CPU æ—¶é—´ | å æ¯” | æ¨¡å— |\n")
                f.write("|------|--------|----------|------|------|\n")
                for i, hotspot in enumerate(analysis.hotspots[:10], 1):
                    f.write(f"| {i} | `{hotspot.function_name}` | "
                           f"{hotspot.cpu_time:.3f}s | "
                           f"**{hotspot.cpu_time_percent:.1f}%** | "
                           f"{hotspot.module} |\n")
                f.write("\n")

            # å†…å­˜æŒ‡æ ‡
            if analysis.memory:
                f.write("## ğŸ’¾ å†…å­˜è®¿é—®æŒ‡æ ‡\n\n")
                if analysis.memory.l1_misses is not None:
                    f.write(f"- **L1 ç¼“å­˜æœªå‘½ä¸­ç‡**: {analysis.memory.l1_misses:.2f}%\n")
                if analysis.memory.l2_misses is not None:
                    f.write(f"- **L2 ç¼“å­˜æœªå‘½ä¸­ç‡**: {analysis.memory.l2_misses:.2f}%\n")
                if analysis.memory.l3_misses is not None:
                    f.write(f"- **L3 ç¼“å­˜æœªå‘½ä¸­ç‡**: {analysis.memory.l3_misses:.2f}%\n")
                if analysis.memory.dtlb_misses is not None:
                    f.write(f"- **DTLB æœªå‘½ä¸­ç‡**: {analysis.memory.dtlb_misses:.2f}%\n")
                if analysis.memory.memory_bandwidth_gb_s is not None:
                    f.write(f"- **å†…å­˜å¸¦å®½**: {analysis.memory.memory_bandwidth_gb_s:.2f} GB/s\n")
                f.write("\n")

            # çº¿ç¨‹æŒ‡æ ‡
            if analysis.threading:
                f.write("## ğŸ§µ çº¿ç¨‹å¹¶è¡ŒæŒ‡æ ‡\n\n")
                if analysis.threading.cpu_utilization is not None:
                    f.write(f"- **CPU åˆ©ç”¨ç‡**: {analysis.threading.cpu_utilization:.1f}%\n")
                if analysis.threading.thread_count is not None:
                    f.write(f"- **çº¿ç¨‹æ•°**: {analysis.threading.thread_count}\n")
                if analysis.threading.wait_time_percent is not None:
                    f.write(f"- **ç­‰å¾…æ—¶é—´å æ¯”**: {analysis.threading.wait_time_percent:.1f}%\n")
                if analysis.threading.load_imbalance is not None:
                    f.write(f"- **è´Ÿè½½ä¸å‡**: {analysis.threading.load_imbalance:.1f}%\n")
                f.write("\n")

            # å¾®æ¶æ„æŒ‡æ ‡
            if analysis.microarch:
                f.write("## âš™ï¸ å¾®æ¶æ„æŒ‡æ ‡\n\n")
                if analysis.microarch.cpi is not None:
                    f.write(f"- **CPI (Cycles Per Instruction)**: {analysis.microarch.cpi:.2f}\n")
                if analysis.microarch.frontend_stall_percent is not None:
                    f.write(f"- **å‰ç«¯åœé¡¿**: {analysis.microarch.frontend_stall_percent:.1f}%\n")
                if analysis.microarch.backend_stall_percent is not None:
                    f.write(f"- **åç«¯åœé¡¿**: {analysis.microarch.backend_stall_percent:.1f}%\n")
                if analysis.microarch.branch_mispred_percent is not None:
                    f.write(f"- **åˆ†æ”¯é¢„æµ‹å¤±è´¥**: {analysis.microarch.branch_mispred_percent:.1f}%\n")
                f.write("\n")

            # ä¼˜åŒ–å»ºè®®
            if analysis.recommendations:
                f.write("## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n\n")
                for i, rec in enumerate(analysis.recommendations, 1):
                    f.write(f"{i}. {rec}\n\n")

            f.write("---\n\n")
            f.write(f"**åˆ†æå·¥å…·**: Intel VTune Profiler\n")
            f.write(f"**ç»“æœç›®å½•**: `{self.result_dir}`\n")

        print(f"âœ“ åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    parser = argparse.ArgumentParser(
        description="Intel VTune ç»“æœåˆ†æå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # åˆ†æå•ä¸ªç»“æœç›®å½•
    python3 analyze_vtune_results.py -d vtune_results/hotspots_koios_dla_like_large

    # åˆ†ææ‰€æœ‰ç»“æœç›®å½•
    python3 analyze_vtune_results.py -a vtune_results/

    # ç”Ÿæˆ JSON æ ¼å¼è¾“å‡º
    python3 analyze_vtune_results.py -d vtune_results/hotspots_test -f json
        """
    )

    parser.add_argument('-d', '--dir', type=str,
                       help='VTune ç»“æœç›®å½•')
    parser.add_argument('-a', '--all', type=str,
                       help='åˆ†ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ VTune ç»“æœ')
    parser.add_argument('-f', '--format', choices=['markdown', 'json'], default='markdown',
                       help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: markdown)')
    parser.add_argument('-o', '--output', type=str,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    if not args.dir and not args.all:
        parser.print_help()
        sys.exit(1)

    # åˆ†æå•ä¸ªç›®å½•
    if args.dir:
        result_dir = Path(args.dir)
        if not result_dir.exists():
            print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {result_dir}", file=sys.stderr)
            sys.exit(1)

        analyzer = VTuneAnalyzer(result_dir)
        analysis = analyzer.analyze()

        # è¾“å‡º
        if args.format == 'json':
            output_file = Path(args.output) if args.output else result_dir / "analysis.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(asdict(analysis), f, indent=2, ensure_ascii=False)
            print(f"âœ“ JSON æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
        else:
            output_file = Path(args.output) if args.output else result_dir / "ANALYSIS_REPORT.md"
            analyzer.generate_markdown_report(output_file)

    # åˆ†ææ‰€æœ‰å­ç›®å½•
    elif args.all:
        base_dir = Path(args.all)
        if not base_dir.exists():
            print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {base_dir}", file=sys.stderr)
            sys.exit(1)

        # æŸ¥æ‰¾æ‰€æœ‰ VTune ç»“æœç›®å½•ï¼ˆåŒ…å« .amplxeproj æˆ–å…¶ä»–æ ‡è¯†æ–‡ä»¶ï¼‰
        result_dirs = [d for d in base_dir.iterdir() if d.is_dir() and not d.name.startswith('.')]

        if not result_dirs:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ° VTune ç»“æœç›®å½•", file=sys.stderr)
            sys.exit(1)

        print(f"æ‰¾åˆ° {len(result_dirs)} ä¸ªç»“æœç›®å½•")

        for result_dir in result_dirs:
            print(f"\nåˆ†æ: {result_dir.name}")
            try:
                analyzer = VTuneAnalyzer(result_dir)
                analysis = analyzer.analyze()

                if args.format == 'json':
                    output_file = result_dir / "analysis.json"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(asdict(analysis), f, indent=2, ensure_ascii=False)
                else:
                    output_file = result_dir / "ANALYSIS_REPORT.md"
                    analyzer.generate_markdown_report(output_file)

            except Exception as e:
                print(f"  é”™è¯¯: {e}", file=sys.stderr)
                continue


if __name__ == "__main__":
    main()
